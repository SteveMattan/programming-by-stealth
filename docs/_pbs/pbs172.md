---
title: Submodules
instalment: 172
miniseries: Git
creators: [bart, allison]
date: 2024-10-26
---
We're making a quick detour back to Git to have a look at one of the more advanced topics I intentionally skipped on our first look at Git because it didn't solve a relevant problem. As we move forward with the XKPasswd project that's changing, and it's also changing in other adjacent contexts, so the time feels ripe to re-visit Git.

One of the things Git's predecessors got badly wrong was nesting — how? By not supporting it! you can't have a Subversion repository within a Subversion repository, but you **can** link a folder in one Git repository to another Git repository. In other words, you can nest Git repositories.

In Git jargon, nested repositories are *Git Submodules*. In other words when you tell Git to link this folder in the repository I'm working on now to that other repostitory over there, you are adding a Git Submodule to your repository. Fundamentally, it really is that simple, **a Git submodule is a link to another Git repository**!

## Matching Podcast Episode

TO DO

## Instalment Resources

*None*

## Why Nest Repositories?

Given how versatile a tool Git is, and how many ways people use it to solve so many different problems, it shouldn't come as a surprise that there are more uses for Git submodules than anyone could possibly list. In light of this, we're going to look at just three example uses that are important to me, and seem relevant to this audience:

1. Deploying Plugin-based Web Apps
2. Subdividing a Document Repository 
3. Including Dependencies in our Code

I've listed these in reverse order of relevance to the PBS series, so we'll finish with the use case we'll use in our examples.

### Use Case 1 — Deploying Plugin-based Web Apps at Scale

In this series, we mostly view things from the developer's point of view. It is called *__programming__ by stealth* after all, but from time to time, we've also looked at the world from the sysadmin's point of view, especially in the [Chezmoi][1] and [Bash scripting][2] mini-series. This example looks at deploying software from a sysadmin's point of view, and it was my first exposure to Git submodules, and really opened my eyes to their power.

Lots of large web apps are built around the idea of a core product that gets expanded by plugins. A good example of this is WordPress, which powers more websites on the Internet than any other publishing platform, including Allison's [podfeet.com][3] website!

You can install WordPress by downloading a ZIP file, expanding it, copying it into a folder on your web server, and editing a single config file to capture some basic information about your web server and website's configuration, and to connect the code to your database server. This will give you the core WordPress web app, and no more. You can add additional themes and plugins by downloading their zip files, extracting them, and uploading them into the appropriate subfolder within the `wp-content` folder in your WordPress instance.

If you configure WordPress with appropriate write permissions to your web server's disk, you can even have WordPress do plugin and theme installs for you, which automates the same process. Once you've given WordPress write permissions to your webserver, you can even configure it to keep your plugins updated automatically!

Setting up WordPress like this works great for small sites, but this setup has some drawbacks, and it won't scale.

Firstly, this entire setup rests on a tradeoff that makes perfect sense for small users — giving any web app write permission on your webserver is inherently dangerous because the app can transform itself into literally any app it likes. You are trusting that the update mechanism is secure; otherwise, your website will inevitably be taken over and converted into something nasty. But, in exchange for accepting that risk, you have freed yourself of the chore of keeping your WordPress install and all your WordPress plugins patched. And, an unpatched WordPress site is even more likely to get taken over than a fully patched one with the power to write to disk.

When you use WordPress in a corporate environment (enterprise, education, publishing, non-profit foundation …) you need to do things differently.

Firstly — you can't accept the risk of granting write access to your web server, so you'll need your IT Department to take over responsibility for patching your site and your entire suite of plugins.

Secondly, you'll need to scale out as well as up. Scaling up is throwing more resources at a single server, scaling out is adding more servers. When you scale out you need to keep the code running on each server in the cluster **identical**, so you can't have each one updating its copy of WordPress and each plugin autonomously, it has to be done in a synchronised and controlled way.

Thirdly, if your WordPress instance forms a core part of your business, you'll need to test your updates before you deploy them. This means you won't only have multiple production servers that need to be kept in perfect sync, you'll also have one or more staging servers where updates get tested before being *pushed* to production.

**BART: GIANT LEAP OF LOGIC HERE - What does Git have to do with WP? I know you talk about it in the next section but it’s a whiplash moment reading this in order* 
You can do all this work without Git, but it can all be done so much more easily with Git, if, and only if you can nest Git repositories. In other words, if, and only if you make use of Git submodules!

#### How Submodules Help BART: I would suggest changing to “How Git (With Submodules) helps”

What we really need is a way to capture and version not just the current state of our copy of WordPress, but the current state of our copy of [WordPress][4], our config file, and the current state of all of our plugins in one Git commit.

When you check out a specific Git branch commit, you need your entire WordPress folder to snap into a known state with a specific version of WordPress, a specific revision of your config, and a specific version of each and every theme & plugin.

The recipe to get here goes something like this:

1. Create a Git repo with two branches you will keep permanently:
   1. `main` — this will be the production version on your site's code that gets automatically deployed to all product web servers in the cluster
   2. `staging` — this will be the version of your site that gets automatically deployed to your test server(s)
2. Add the official WordPress Git repo as a remote named `upstream`.
3. Check out your desired version of WordPress from the `upstream` remote into your `staging` branch
4. Add your config file, and commit
5. Add a submodule for each theme and plugin, checking out the exact version of each you want, and commit again. **BART: You’re using submodule without telling us what the are yet**
6. Push your local `staging` branch to your Git server to trigger a deployment to your test servers, and make sure it all works.
7. Merge your `staging` branch into your `main` branch and push again, triggering a deployment to your production servers.

This assumes your sysadmins have used Git's trigger features to handle the work of actually deploying the code to the server, and making any needed substitutions to tweak the config for staging and production environments. This is all bread and butter stuff for sysadmins that get wrapped up in the jargon term *CI-CD* with stands for *Constant Integration-Constant Deployment*, and [GitHub Actions][5] are an example of a CI-CD service.

What's very important to note here is that when you deploy your repository to your webservers, they all get the **identical** versions of each of the following:

1. Core WordPress
2. Your Config
3. Each and every installed theme and plugin

This is already cool, but the real magic comes in how you can now handle updates.

To update core WordPress, you can now follow these basic steps:

1. Create a new WIP branch from your `main` branch and check it out
2. Merge the desired version of WordPress into your WIP branch from the `upstream` remote, i.e. from the official WordPress Git repo
3. Merge your WIP branch into your `staging` branch and push to trigger a deployment to your test environment
4. Test!
5. Merge your WIP branch into your `main` branch, and push to trigger a deployment to **BART - you didn’t finish this sentence**

This doesn't make obvious use of submodules, but updating themes and plugins in this world does. The process to handle theme and plugin updates now becomes:

1. Create a new WIP branch from your `main` branch and check it out
2. For each theme and plugin you want to update, repeat the following:
   1. Change into the relevant folder — the `git` command is now interacting with a separate mini Git repo inside your main Git repo, and that mini Git repo has the official Git repo for the theme/plugin as it's default remote named `origin`
   2. Fetch all new commits, tags, and branches from the theme/plugin's official GitHub repo with a `git fetch`
   3. Check out the desired branch, tag, or commit into the mini subrepo
4. Change back to the root of your main Git repo, and commit — this captures the new desired state for each theme and plugin you updated
5. Merge your WIP branch into your `staging` branch and push to trigger a deployment to your test servers
6. Test!
7. Merge your WIP branch into our `main` brach and push to trigger a deployment to your live website

Finally, let's look at how easy it is to add another web server to your production or testing cluster — all you need to do is check out either your `main` or `staging` branch, and you have a full copy of your site's entire codebase ready to go!

With my work hat on I never did this with WordPress, but it did completely change how I worked with a different, even bigger web app with even more plugins — the open source Virtual Learning Environment [Moodle][6]. I started my sysadmin career manually managing a Moodle deployment by downloading and extracting ZIP files and then using things like `rsync` to move files around, and when I transitioned away from being a sysadmin to become a cybersecurity specialist a little over two decades later, I was managing the same Moodle instance via Git with submodules. Wow, what a difference!

### Use Case 2 — Breaking up a Document Repository

While we may primarily think of Git as a developer tool, and perhaps also a sysadmin tool, it is also a powerful tool for writers. These very show notes are [versioned in Git][7]!

There is an evolving trend to move away from traditional database-driven content management systems (CMSes) like WordPress to move towards so-called *static site generators*, these are basically folders of text files, usually in Markdown, that get converted into a basic HTML, CSS & JavaScript website each time a page is changed. With Git, these kinds of folders-of-files can be automatically deployed to the web using CI-CD tools, just like in our WordPress usevcase above. In fact, that is exactly how this web page you are reading right now came to be. I am writing this text in [Markdown][8] using [Typora][9] on my Mac, and when I get to the next logical break in the flow I'll commit my changes on a WIP branch. When Allison is done editing the matching podcast episode she'll merge the WIP branch for this instalment into the main branch, triggering [GitHub Pages][10] to build a fresh copy of the entire PBS website from the folder of Markdown files that are versioned in Git. This is Git+CI-CD in action for publishing!

None of this requires Git submodules, but now imagine using a static site generator to build a much larger site, one for an organisation that has sub-divisions of some kind. You want to allow each section of the organisation to manage their own web content, but **only** their own web content, and you may want to interject some kind of review process. One way to achieve this would be with Git submodules.

There would be one master Git repository controlled by the part of the organisation that is ultimately responsible for the entire website, and they would connect their repository to test and production versions of the website using some kind of CI-CD pipeline. They would then create Git submodules for each sub-division within the organisation, each mapped to an appropriate folder in the website's hierarchy.

Remember that a sub-module is just a Git repository checked out within another Git repository, it is fundamentally no different to any other Git repository, so it can be cloned by itself just like any other repository.

In this scenario, each sub-division of the organisation works on the Git repository representing their part of the site as a stand-alone Git repository. They can't see or edit any other department's pages. They can implement their own processes and procedures within their repo, but there needs to be some kind of agreed way for their repo to signal to the the repo for the entire site that there is a change ready to be incorporated into the main site.

Probably the most logical approach would be to add a CI-CD trigger to each sub division's repository that fires when a commit is added to the `main` branch. This trigger could cause the repo for the full site to pull the changes into their `staging` branch, publish the changes to the test website, and open an issue in some kind of issue tracker requesting review. Once review is approved, the change could be merged into the site's main branch and deployed to the production website.

So far, this does not seem particularly relevant to this series, but there is another way folders of Markdown files are used to build structured content — knowledge base apps like the open source [Obsidian][11].

I've become very fond of using Markdown+Git as my writing environment, and I want to capture all the segments I produce for my own podcasts and for other people's podcasts in a single versioned Obsidian knowledge base. The addition of some YAML front matter lets me add context to these contributions, so I can quickly answer useful questions like:

* *What was the most recent segment I contributed on AI?*
* *How many EVs have I reviewed on the Kilowatt Podcast?*
* *What segments did I produce in June 2024?*
* *Build a list of the links to every segment I've produced about VPNs*

And so on and so forth.

If I was the solo writer for all this content it would work great, but I have a long-standing relationship with Allison where we collaboratively edit notes for Security Bits and other guest segments I write for the NosillaCast.

Because I trust Allison completely, I had no objection to giving her full access to my full knowledge base, which worked great for me, but things looked rather different from Allison's side. Instead of seeing one folder with sensible sub-folders for Security bits and other segments, she saw a massive wall of folders, one for every network I contribute to, and only one of them was relevant to her. She had to clone all those folders onto her Mac, and navigate down into an irrelevant hierarchy just to get to the Security Bits notes!

Solving this problem for both of us is what triggered this revival of the Git mini-series 🙂

Now that we know about Git sub-modules the answer is obvious — I create a dedicated repo for just my collaborations with Allison, and I add it to my master knowledge base as a sub-module.

In this setup, I still have my single folder of Markdown files that Obsidian can display and process as a single knowledge base, and Allison sees a traditional Git repository with just the files relevant to my contributions to her shows!

### Use Case 3 — Including Dependencies in our Code

Let's now firmly place our developer hat on our heads and look at how we can choose to include external resources in our coding projects.

We've seen that we want to include published third-party libraries like [jQuery][12] or [Bootstrap][13] we can choose to avoid the whole question by simply linking to them on a public content delivery network without ever bringing them into our projects at all. Or, we can use a package manager like [NPM][14] where we have a versioned JSON file that specifies the packages our code depends on, and anyone trying to use our code needs to run NPM to fetch the packages after they clone our repo. Or, like the current beta version of the XKPasswd project does, we can use a bundler like [Webpack][15] to re-package the external resources within our published code.

All of these options work great when we're read-only consumers of publicly available code, what happens when either or both of those things change? What if we need to contribute back to the code we are incorporating, and/or it is not published publicly?

This is something we will soon need to address in the [XKPasswd project][16]. As I write this instalment the code for the entire XKPasswd JavaScript port is contained in a single Git repository — that includes both the open source library itself and the beta version of the public web interface. The intention was always to have the library itself be stand-alone so it can be incorporated into other projects, one of which will be the final public version of the website.

This change will simplify the structure and build process for the library's repository, but it will require the repository for the web interface to import the code for the library. In the medium to long term this will probably be done using a package manager like NPM because the library will become a stable published package like jQuery, but in the short term it seems likely contributors will want to edit both the library and the web interface simultaneously because both will be under active development simultaneously. While no final decision has been made on exactly how these repos will be structure, my current preference is to add the repo for the library to the repo for the website as a Git submodule.

This handles the situation where all the code is public, and we want read-write access to all parts. What about scenarios where none of the code is public?

The classic example here is a piece of internal code within an organisation that is used in multiple projects. Imagine an organisation that has multiple web apps, and they want them all to have a consistent branding. One way to do this would be to have a standard theme versioned in its own repository that is then included into the repositories for each web app. This is private code where developers on any project may want to contribute to the shared resource, so a package manager, even an entirely private one, seems like a poor fit. A much better approach would be to include the standard theme into each project as a Git sub-module, allowing all developers to contribute to both their own app and the shared theme simultaneously from within their own repositories.

In the next instalment we're going to use this final use case as our worked example as we explore how to actually use Git sub-modules.

## Final Thoughts

Hopefully, you now understand why Git sub-modules are so powerful, and why you might want to take the time to learn how to use them. That sets us up well for the next instalment where we'll learn the `git` commands needed for working with sub-modules. Learning the commands will give you the lexicon Git uses when working with sub-modules, which should help you understand the same functionality in whatever Git GUI you prefer to use.

[1]:	pbs121
[2]:	pbs143
[3]:	https://podfeet.com
[4]:	https://wordpress.org
[5]:	https://docs.github.com/en/actions/about-github-actions/understanding-github-actions
[6]:	https://moodle.org
[7]:	https://github.com/bartificer/programming-by-stealth
[8]:	https://www.markdownguide.org
[9]:	https://typora.io
[10]:	https://pages.github.com
[11]:	https://obsidian.md
[12]:	https://jquery.com
[13]:	https://getbootstrap.com
[14]:	https://pbs.bartificer.net/pbs127
[15]:	pbs137
[16]:	https://www.xkpasswd.net